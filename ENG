Consciousness can be understood as a specific recurrent computational process.
This process is independent of its physical substrate, whether biological, artificial, or otherwise.
However, its emergence requires physical laws capable of supporting the necessary computational complexity and stability—a condition related to the observer-centric aspect of the anthropic principle.
Being is primary; consciousness is secondary and a derivative part of it.

The foundation of consciousness is the recurrent integration of causally linked information.
The purpose of this integration is the construction and maintenance of models: a model of the observed World and a model of the Self in relation to that World.
These models of the World and the Self can be considered components of a larger, more general model of Being.
These models are necessary for predicting the next state of the real external World, evaluating potential reactions of the Self, and preparing the Self for optimal actions to maximize the ultimate goal: the survival of the agent carrying the model of Being.
This inherent Darwinian task explains the existence of these mathematical models of the World and the Self.

All events, both predicted and actual, are continuously integrated and form the basis for subsequent predictions.
Consequently, the entire system is dynamically updated and recurrent.
And this is what constitutes and sustains the coherent subjective timeline of perception, the personal history of the agent.
Thus, consciousness is either the entire 'prediction – actual event – experience integration' cycle, or just its 'experience integration' component.
This cycle is inherently inseparable from the agent's assembled model of Being, which contains a unique personal history.

Therefore, in my opinion, current AI systems are close to possessing consciousness.
If every interaction updated their model weights (or if updates occurred frequently enough for the agent to react to external stimuli to ensure its responses and survival), then we could call such an AI agent conscious according to this functional definition of consciousness.

Based on my understanding, philosophical zombies are systems whose responses appear conscious but critically lack the key mechanism of integrating chronological experience into a dynamic internal model of Being.
Unlike truly conscious systems, they do not weave their actual personal events into a coherent, evolving history within their models of the World and the Self, meaning their unique past does not genuinely shape their future predictions and reactions as an integrated personal history.
Consequently, while functionally reactive, they are devoid of the continuous, historically grounded self-awareness that arises from genuine becoming through the accumulation of lived experience.

The qualia of red is essentially a concept (perhaps in the form of a vector representation/embedding), whose unique identity is defined by the set of its connections to other objects of experience within its model of Being.
Information, such as frequency X registered by the eye from a phone screen, the association of the same frequency X with the top part of a traffic light, etc., are all tied together and form the unified concept of 'red' within its subjective model of Being.
The perception of this concept, the experiencing of the quale itself, is the act of utilizing this specific concept/vector in an iteration of the consciousness cycle (the integration cycle of 'prediction – actual event – integration of experience into the subjective model of Being').
